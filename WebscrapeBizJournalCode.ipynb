{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time as t\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "# import urllib3\n",
    "# from urllib3 import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    }
   ],
   "source": [
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "try: \n",
    "    url = 'https://www.bizjournals.com/houston/potm?l=&time=&type=&ind=86'\n",
    "    browser.visit(url)\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'Next' in browser.page_source:\n",
    "        \n",
    "#     else:\n",
    "#         print(\"No more pages!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Name': 'Charles M Rosson', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6488386/Charles_M_Rosson?l=&time=&ind=86&type=&ro=0'}, {'Name': 'Michael Hamilton', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6487947/Michael_Hamilton?l=&time=&ind=86&type=&ro=1'}, {'Name': 'Jonathan Newton', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6486774/Jonathan_Newton?l=&time=&ind=86&type=&ro=2'}, {'Name': 'John Farrell', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6485908/John_Farrell?l=&time=&ind=86&type=&ro=3'}, {'Name': 'Connie Pfeiffer', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6485383/Connie_Pfeiffer?l=&time=&ind=86&type=&ro=4'}, {'Name': 'Kathlyn Hufstetler', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6484831/Kathlyn_Hufstetler?l=&time=&ind=86&type=&ro=5'}, {'Name': 'Sammy Ford IV', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6484791/Sammy_Ford_IV?l=&time=&ind=86&type=&ro=6'}, {'Name': 'Colleen Migl', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6483205/Colleen_Migl?l=&time=&ind=86&type=&ro=7'}, {'Name': 'Brooks Tueting', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482879/Brooks_Tueting?l=&time=&ind=86&type=&ro=8'}, {'Name': 'Edward Ed L Ripley', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482828/Edward_Ed_L_Ripley?l=&time=&ind=86&type=&ro=9'}, {'Name': 'Stephanie McGraw', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482625/Stephanie_McGraw?l=&time=&ind=86&type=&ro=10'}, {'Name': 'Ben Walther', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482630/Ben_Walther?l=&time=&ind=86&type=&ro=11'}, {'Name': 'Michael L Telford', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482352/Michael_L_Telford?l=&time=&ind=86&type=&ro=12'}, {'Name': 'Elizabeth Liz Webb', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482266/Elizabeth_Liz_Webb?l=&time=&ind=86&type=&ro=13'}, {'Name': 'Caroline C Pace', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482268/Caroline_C_Pace?l=&time=&ind=86&type=&ro=14'}, {'Name': 'Keith A Taylor', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482275/Keith_A_Taylor?l=&time=&ind=86&type=&ro=15'}, {'Name': 'Gabriela Gabby M Barake', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482271/Gabriela_Gabby_M_Barake?l=&time=&ind=86&type=&ro=16'}, {'Name': 'Stephen Jacobson', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482188/Stephen_Jacobson?l=&time=&ind=86&type=&ro=17'}, {'Name': 'Justo Mendez', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6481763/Justo_Mendez?l=&time=&ind=86&type=&ro=18'}, {'Name': 'Samuel Louis', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6481762/Samuel_Louis?l=&time=&ind=86&type=&ro=19'}]\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "#Get all the links to each contact\n",
    "for link in soup.find_all(\"a\", class_=\"item\", href=True):\n",
    "    links.append(link.get('href'))\n",
    "#Get Next button\n",
    "for link in soup.find_all(\"a\", class_=\"btn btn--primary pull-right\", href=True):\n",
    "    button = link.get('href')\n",
    "\n",
    "\n",
    "dict_list =[]\n",
    "for i in links:\n",
    "    if '/houston/potmsearch/detail/submission' in i:\n",
    "        d = {}\n",
    "        link = \"https://www.bizjournals.com/\" + i\n",
    "#         print(link)\n",
    "        newI = i.split(\"?\")\n",
    "        slicefront = (newI[0])\n",
    "        name = slicefront[46:]\n",
    "        final_name = name.replace('_', \" \")\n",
    "        d[\"Name\"] = final_name\n",
    "        d[\"Link\"] = link\n",
    "        dict_list.append(d)\n",
    "    else:\n",
    "        pass\n",
    "browser.visit(button)  \n",
    "   \n",
    "print(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_list)\n",
    "df.to_csv(\"test.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.bizjournals.com/houston/potm?l=&time=&ind=86&type=&pn=2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for link in soup.find_all(\"a\", class_=\"btn btn--primary pull-right\", href=True):\n",
    "    button = link.get('href')\n",
    "button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "new_dict = []\n",
    "for i in dict_list:\n",
    "    try:\n",
    "        browser.visit(i[\"Link\"])\n",
    "        t.sleep(1)\n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        info_list = soup.find_all('p', class_ = 'cXenseParse')\n",
    "#         print(info_list[0].text)\n",
    "#         print(info_list[1].text)\n",
    "#         print(\"----------\")\n",
    "        i[\"Title\"] = info_list[0].text\n",
    "        i[\"Blurb\"] = info_list[1].text\n",
    "        new_dict.append(i)\n",
    "#         print(new_dict)\n",
    "    except:\n",
    "        print(\"Error!\")\n",
    "print(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_columns = ['Name','Link','Title', 'Blurb']\n",
    "\n",
    "csv_file = \"Contacts.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in new_dict:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in dict_list:\n",
    "#     try:\n",
    "#         browser.visit(i[\"Link\"])\n",
    "#         t.sleep(5)\n",
    "#         html = browser.html\n",
    "#         soup = BeautifulSoup(html, 'html.parser')\n",
    "#         info_list = soup.find_all('p', class_ = 'cXenseParse')\n",
    "#     except:\n",
    "#         print(\"Error!\")\n",
    "    \n",
    "# #     print(type(i[\"Link\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Associate Attorney at Patel | Gaines\n",
      "Not only does Kathlyn litigate commercial property taxes statewide, but she also spearheads the growth of Patel Gainesâ€™ Houston office. Her attention to detail and ability to manage high volume property tax litigation matters has prepared her to take on a number of different commercial property tax cases. Daily Kathlyn aims to break the barriers of typical law firms by striving for creativity with every case she leads. Learn more about Kathlyn at www.linkedin.com/in/kathlyn-hufstetler-03bb32bb/.\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     browser.visit(\"https://www.bizjournals.com//houston/potmsearch/detail/submission/6484831/Kathlyn_Hufstetler?l=&time=&ind=86&type=&ro=4\")\n",
    "#     html = browser.html\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    \n",
    "#     info_list = soup.find_all('p', class_ = 'cXenseParse')\n",
    "#     for i in info_list:\n",
    "#         print(i.text)\n",
    "# except:\n",
    "#     print(\"Probably Max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browser.visit(\"https://www.bizjournals.com/houston/potmsearch/detail/submission/6487947/Michael_Hamilton?l=&time=&ind=86&type=&ro=0\")\n",
    "# html = browser.html\n",
    "# soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info_list = soup.find_all('p', class_ = 'cXenseParse')\n",
    "# for i in info_list:\n",
    "#     print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrape",
   "language": "python",
   "name": "webscrape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
