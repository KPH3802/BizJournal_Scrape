{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time as t\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "# import urllib3\n",
    "# from urllib3 import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    }
   ],
   "source": [
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "try: \n",
    "    url = 'https://www.bizjournals.com/houston/potm?l=&time=&type=&ind=86'\n",
    "    browser.visit(url)\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'Next' in browser.page_source:\n",
    "        \n",
    "#     else:\n",
    "#         print(\"No more pages!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Name': 'Charles M Rosson', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6488386/Charles_M_Rosson?l=&time=&ind=86&type=&ro=0'}, {'Name': 'Michael Hamilton', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6487947/Michael_Hamilton?l=&time=&ind=86&type=&ro=1'}, {'Name': 'Jonathan Newton', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6486774/Jonathan_Newton?l=&time=&ind=86&type=&ro=2'}, {'Name': 'John Farrell', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6485908/John_Farrell?l=&time=&ind=86&type=&ro=3'}, {'Name': 'Connie Pfeiffer', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6485383/Connie_Pfeiffer?l=&time=&ind=86&type=&ro=4'}, {'Name': 'Kathlyn Hufstetler', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6484831/Kathlyn_Hufstetler?l=&time=&ind=86&type=&ro=5'}, {'Name': 'Sammy Ford IV', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6484791/Sammy_Ford_IV?l=&time=&ind=86&type=&ro=6'}, {'Name': 'Colleen Migl', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6483205/Colleen_Migl?l=&time=&ind=86&type=&ro=7'}, {'Name': 'Brooks Tueting', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482879/Brooks_Tueting?l=&time=&ind=86&type=&ro=8'}, {'Name': 'Edward Ed L Ripley', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482828/Edward_Ed_L_Ripley?l=&time=&ind=86&type=&ro=9'}, {'Name': 'Stephanie McGraw', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482625/Stephanie_McGraw?l=&time=&ind=86&type=&ro=10'}, {'Name': 'Ben Walther', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482630/Ben_Walther?l=&time=&ind=86&type=&ro=11'}, {'Name': 'Michael L Telford', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482352/Michael_L_Telford?l=&time=&ind=86&type=&ro=12'}, {'Name': 'Elizabeth Liz Webb', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482266/Elizabeth_Liz_Webb?l=&time=&ind=86&type=&ro=13'}, {'Name': 'Caroline C Pace', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482268/Caroline_C_Pace?l=&time=&ind=86&type=&ro=14'}, {'Name': 'Keith A Taylor', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482275/Keith_A_Taylor?l=&time=&ind=86&type=&ro=15'}, {'Name': 'Gabriela Gabby M Barake', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482271/Gabriela_Gabby_M_Barake?l=&time=&ind=86&type=&ro=16'}, {'Name': 'Stephen Jacobson', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6482188/Stephen_Jacobson?l=&time=&ind=86&type=&ro=17'}, {'Name': 'Justo Mendez', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6481763/Justo_Mendez?l=&time=&ind=86&type=&ro=18'}, {'Name': 'Samuel Louis', 'Link': 'https://www.bizjournals.com//houston/potmsearch/detail/submission/6481762/Samuel_Louis?l=&time=&ind=86&type=&ro=19'}]\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "#Get all the links to each contact\n",
    "for link in soup.find_all(\"a\", class_=\"item\", href=True):\n",
    "    links.append(link.get('href'))\n",
    "#Get Next button\n",
    "for link in soup.find_all(\"a\", class_=\"btn btn--primary pull-right\", href=True):\n",
    "    button = link.get('href')\n",
    "\n",
    "\n",
    "dict_list =[]\n",
    "for i in links:\n",
    "    if '/houston/potmsearch/detail/submission' in i:\n",
    "        d = {}\n",
    "        link = \"https://www.bizjournals.com/\" + i\n",
    "#         print(link)\n",
    "        newI = i.split(\"?\")\n",
    "        slicefront = (newI[0])\n",
    "        name = slicefront[46:]\n",
    "        final_name = name.replace('_', \" \")\n",
    "        d[\"Name\"] = final_name\n",
    "        d[\"Link\"] = link\n",
    "        dict_list.append(d)\n",
    "    else:\n",
    "        pass\n",
    "browser.visit(button)  \n",
    "   \n",
    "print(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'TEstdir/test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-19870ff1b01f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TEstdir/test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/webscrape/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/webscrape/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/webscrape/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'TEstdir/test.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dict_list)\n",
    "df.to_csv(\"Tstdir/test.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.bizjournals.com/houston/potm?l=&time=&ind=86&type=&pn=2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for link in soup.find_all(\"a\", class_=\"btn btn--primary pull-right\", href=True):\n",
    "    button = link.get('href')\n",
    "button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "new_dict = []\n",
    "for i in dict_list:\n",
    "    try:\n",
    "        browser.visit(i[\"Link\"])\n",
    "        t.sleep(1)\n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        info_list = soup.find_all('p', class_ = 'cXenseParse')\n",
    "#         print(info_list[0].text)\n",
    "#         print(info_list[1].text)\n",
    "#         print(\"----------\")\n",
    "        i[\"Title\"] = info_list[0].text\n",
    "        i[\"Blurb\"] = info_list[1].text\n",
    "        new_dict.append(i)\n",
    "#         print(new_dict)\n",
    "    except:\n",
    "        print(\"Error!\")\n",
    "print(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_columns = ['Name','Link','Title', 'Blurb']\n",
    "\n",
    "csv_file = \"Contacts.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in new_dict:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in dict_list:\n",
    "#     try:\n",
    "#         browser.visit(i[\"Link\"])\n",
    "#         t.sleep(5)\n",
    "#         html = browser.html\n",
    "#         soup = BeautifulSoup(html, 'html.parser')\n",
    "#         info_list = soup.find_all('p', class_ = 'cXenseParse')\n",
    "#     except:\n",
    "#         print(\"Error!\")\n",
    "    \n",
    "# #     print(type(i[\"Link\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Associate Attorney at Patel | Gaines\n",
      "Not only does Kathlyn litigate commercial property taxes statewide, but she also spearheads the growth of Patel Gaines’ Houston office. Her attention to detail and ability to manage high volume property tax litigation matters has prepared her to take on a number of different commercial property tax cases. Daily Kathlyn aims to break the barriers of typical law firms by striving for creativity with every case she leads. Learn more about Kathlyn at www.linkedin.com/in/kathlyn-hufstetler-03bb32bb/.\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     browser.visit(\"https://www.bizjournals.com//houston/potmsearch/detail/submission/6484831/Kathlyn_Hufstetler?l=&time=&ind=86&type=&ro=4\")\n",
    "#     html = browser.html\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    \n",
    "#     info_list = soup.find_all('p', class_ = 'cXenseParse')\n",
    "#     for i in info_list:\n",
    "#         print(i.text)\n",
    "# except:\n",
    "#     print(\"Probably Max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browser.visit(\"https://www.bizjournals.com/houston/potmsearch/detail/submission/6487947/Michael_Hamilton?l=&time=&ind=86&type=&ro=0\")\n",
    "# html = browser.html\n",
    "# soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info_list = soup.find_all('p', class_ = 'cXenseParse')\n",
    "# for i in info_list:\n",
    "#     print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrape",
   "language": "python",
   "name": "webscrape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
